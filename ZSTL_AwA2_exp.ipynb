{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597834696181",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import itertools\n",
    "import tqdm\n",
    "# import hypergrad as hg\n",
    "from mlmodel import *\n",
    "import utils\n",
    "import numpy as np\n",
    "from sparsemax import Sparsemax\n",
    "from argparse import ArgumentParser\n",
    "from ZSTL_model import ZSTL\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FuncRecursiveNet([\n",
    "    FLinearLayer(1, True)\n",
    "])\n",
    "shape_record = {0: [(1, 2049)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_size = 5\n",
    "train_size = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "50 50\n<class 'dict'>\n"
    }
   ],
   "source": [
    "filename = '../ZSTL_Data/Animals_with_Attributes2/splitedTask/task_train_data_standard.pickle'\n",
    "#filename = '../ZSTL_Data/CUB_200_2011/CUB_200_2011/splitedTask/task_train_data_standard.pickle'\n",
    "with open(filename, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "print(len(dataset), len(list(dataset.keys())))\n",
    "print(type(dataset))\n",
    "\n",
    "total_len = len(dataset)\n",
    "test_size = total_len - kb_size - train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check stored data correctness\n",
    "def check_attr_correct(num_task, dataset, task_attr_byID, model):\n",
    "    task_train_data = {}\n",
    "    task_test_data = {}\n",
    "    task_val_data = {}\n",
    "    for t in range(num_task):\n",
    "        cur_attr = dataset[t+1][0]\n",
    "        cur_param = utils.toTensor(dataset[t+1][1])\n",
    "        cur_x = utils.toTensor(dataset[t+1][2])\n",
    "        cur_y = dataset[t+1][3]\n",
    "        print((cur_attr==task_attr_byID[t+1]).all())\n",
    "\n",
    "\n",
    "        reshaped_w = utils.reshape_w(cur_param, shape_record)\n",
    "        pred = model(reshaped_w, cur_x)\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred[pred>=0.5] = torch.ones_like(pred[pred>=0.5])\n",
    "        pred[pred<0.5] = torch.zeros_like(pred[pred<0.5])\n",
    "        print(np.sum(utils.toNumpy(pred)==cur_y)/100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_attributes = '../ZSTL_Data/Animals_with_Attributes2/predicate-matrix-continuous.txt'\n",
    "def gen_attr(path_attributes):\n",
    "    data_attributes = pd.read_csv(path_attributes, sep=\"\\n\", header=None)\n",
    "    print(data_attributes)\n",
    "    lst = []\n",
    "    task_attr_byID = {}\n",
    "    i = 1\n",
    "    for r in data_attributes.iterrows():\n",
    "        # print(len(r), )\n",
    "        s = r[1].to_numpy()\n",
    "        # print(len(s[0].split()), s[0].split())\n",
    "        print(len(s[0].split()))\n",
    "        task_attr_byID[i] = np.array([float(a) for a in s[0].split()])\n",
    "        print(task_attr_byID[i].shape)\n",
    "        i += 1\n",
    "    return task_attr_byID\n",
    "\n",
    "#task_attr_byID = gen_attr(path_attributes)\n",
    "#check_attr_correct(total_len, dataset, task_attr_byID, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5\n35\n10\n"
    }
   ],
   "source": [
    "np.random.seed(666)\n",
    "indx = [ x+1 for x in range(len(dataset))]\n",
    "support_indx = list(np.random.choice(indx, size=kb_size, replace=False))\n",
    "print(len(support_indx))\n",
    "temp = [x for x in indx if x not in support_indx]\n",
    "train_indx = list(np.random.choice(temp, size=train_size, replace=False))\n",
    "temp = [x for x in temp if x not in train_indx]\n",
    "print(len(train_indx))\n",
    "test_indx = temp\n",
    "print(len(test_indx))\n",
    "\n",
    "\n",
    "support_data = utils.Dataset([dataset[d] for d in support_indx])\n",
    "train_data = utils.Dataset([dataset[d] for d in train_indx])\n",
    "test_data = utils.Dataset([dataset[d] for d in test_indx])\n",
    "support_loader = DataLoader(support_data, batch_size=kb_size, shuffle=False)\n",
    "train_loader = DataLoader(train_data, batch_size=train_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "85\n2049\n{'rho': 1e-05, 'mu': 1e-05, 'loss': 'binary class', 'outer lr': 0.001, 'align lr': 0.0001, 'dm': 85, 'd': 2049, 'model_shape': {0: [(1, 2049)]}, 'atten_activation': 'Sparsemax'}\ninit mean test metric 0.5980000000000001; align loss 0.28833961486816406\n1/500 o_loss 2.3319798475561715; m train metric 0.5541428571428572; m test metric 0.623; align loss  0.2568095326423645\n10/500 o_loss 1.07951808829717; m train metric 0.6971428571428571; m test metric 0.6925000000000001; align loss  0.25673040747642517\n20/500 o_loss 0.9048650095831753; m train metric 0.7311428571428572; m test metric 0.7154999999999999; align loss  0.25661975145339966\n30/500 o_loss 0.7600210903561674; m train metric 0.7484285714285716; m test metric 0.7100000000000002; align loss  0.2565110921859741\n40/500 o_loss 0.648300460991907; m train metric 0.7994285714285716; m test metric 0.7155000000000001; align loss  0.2564249634742737\n50/500 o_loss 0.5743968977642778; m train metric 0.8138571428571426; m test metric 0.6965; align loss  0.256338506937027\n60/500 o_loss 0.5195297108285428; m train metric 0.8295714285714287; m test metric 0.6865; align loss  0.25624948740005493\n70/500 o_loss 0.47513970419303014; m train metric 0.8425714285714287; m test metric 0.6705; align loss  0.25615501403808594\n80/500 o_loss 0.43790397244488954; m train metric 0.8539999999999999; m test metric 0.663; align loss  0.2560470700263977\n90/500 o_loss 0.40582142272074373; m train metric 0.8615714285714284; m test metric 0.649; align loss  0.25592681765556335\n100/500 o_loss 0.3780398920124363; m train metric 0.8698571428571428; m test metric 0.6385; align loss  0.255791574716568\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b656e9afa20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mZSTL_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZSTL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mZSTL_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Thesis_code/ZSTL_Master_Thesis/ZSTL_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, test_loader, max_iter)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mtest_l_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mtrain_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "support_a, support_w, support_x, support_y = next(iter(support_loader))\n",
    "support_a, support_w, support_x, support_y = support_a.float(), support_w.float(), support_x.float(), support_y.float()\n",
    "support_a = support_a.squeeze().t()\n",
    "support_w = support_w.squeeze().t()\n",
    "dm = support_a.size()[0]\n",
    "print(dm)\n",
    "d  = support_w.size()[0]\n",
    "print(d)\n",
    "\n",
    "param_dict = {}\n",
    "param_dict['rho'] = 1e-5\n",
    "param_dict['mu'] = 1e-5\n",
    "param_dict['loss'] = 'binary class'\n",
    "param_dict['outer lr'] = 1e-3\n",
    "param_dict['align lr'] = 1e-4\n",
    "param_dict['dm'] = dm\n",
    "param_dict['d'] = d\n",
    "param_dict['model_shape'] = shape_record\n",
    "param_dict['atten_activation'] = 'Sparsemax'\n",
    "print(param_dict)\n",
    "\n",
    "\n",
    "ZSTL_model = ZSTL(support_w, support_a, support_x, net, param_dict)\n",
    "ZSTL_model.train(train_loader, test_loader, max_iter=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "312\n2049\n20\n120\n120\n20\nnum of hp  16\nrho for w_kb 0.1; mu for a_kb 0.1;\ninit mean test metric 0.5762499999999999; align loss 258.3763427734375\n1/1500 o_loss 17.96778246735533; m train metric 0.613333333333333; m test metric 0.6143749999999999; align loss  250.96774291992188\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-32df71be0cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain_splited_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_splited_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_indx_splited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbest_hp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_select_binClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_splited_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_hp '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_hp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis_code/ZSTL_Master_Thesis/utils.py\u001b[0m in \u001b[0;36mhp_select_binClass\u001b[0;34m(train_loader, val_loader, support_loader, d, dm, model, model_shape)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mZSTL_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZSTL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mZSTL_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mmean_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZSTL_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_shot_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis_code/ZSTL_Master_Thesis/ZSTL_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, test_loader, max_iter)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtrain_l_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mo_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "indx = train_indx\n",
    "val_indx = list(np.random.choice(indx, size=20, replace=False))\n",
    "print(len(val_indx))\n",
    "train_indx_splited = [x for x in indx if x not in val_indx]\n",
    "print(len(train_indx_splited))\n",
    "\n",
    "val_data = utils.Dataset([dataset[d] for d in val_indx])\n",
    "train_splited_data = utils.Dataset([dataset[d] for d in train_indx_splited])\n",
    "val_loader = DataLoader(val_data, batch_size=len(val_indx), shuffle=True)\n",
    "train_splited_loader = DataLoader(train_splited_data, batch_size=len(train_indx_splited), shuffle=True)\n",
    "\n",
    "best_hp = utils.hp_select_binClass(train_splited_loader, val_loader, support_loader, d, dm, net, shape_record)\n",
    "print('best_hp ', best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2049 312\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_dict = {}\n",
    "param_dict['rho'] = best_hp['rho']\n",
    "param_dict['mu'] = best_hp['mu']\n",
    "param_dict['loss'] = 'binary class'\n",
    "param_dict['outer lr'] = 1e-3\n",
    "param_dict['align lr'] = 1e-4\n",
    "param_dict['dm'] = dm\n",
    "param_dict['d'] = d\n",
    "param_dict['model_shape'] = shape_record\n",
    "param_dict['atten_activation'] = 'Sparsemax'\n",
    "print(param_dict)\n",
    "\n",
    "\n",
    "ZSTL_model = ZSTL(support_w, support_a, support_x, net, param_dict)\n",
    "ZSTL_model.train(train_loader, test_loader, max_iter=1800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}