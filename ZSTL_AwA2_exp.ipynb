{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598117119775",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import itertools\n",
    "import tqdm\n",
    "# import hypergrad as hg\n",
    "from mlmodel import *\n",
    "import utils\n",
    "import numpy as np\n",
    "from sparsemax import Sparsemax\n",
    "from argparse import ArgumentParser\n",
    "from ZSTL_GPU import ZSTL\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\n"
    }
   ],
   "source": [
    "net = FuncRecursiveNet([\n",
    "    FLinearLayer(1, True)\n",
    "])\n",
    "shape_record = {0: [(1, 2049)]}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_size = 10\n",
    "train_size = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "200 200\n<class 'dict'>\n"
    }
   ],
   "source": [
    "#filename = '../ZSTL_Data/Animals_with_Attributes2/splitedTask/task_train_data_standard.pickle'\n",
    "filename = '../ZSTL_Data/CUB_200_2011/CUB_200_2011/splitedTask/task_train_data_standard.pickle'\n",
    "with open(filename, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "print(len(dataset), len(list(dataset.keys())))\n",
    "print(type(dataset))\n",
    "\n",
    "total_len = len(dataset)\n",
    "test_size = total_len - kb_size - train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check stored data correctness\n",
    "def check_attr_correct(num_task, dataset, task_attr_byID, model):\n",
    "    task_train_data = {}\n",
    "    task_test_data = {}\n",
    "    task_val_data = {}\n",
    "    for t in range(num_task):\n",
    "        cur_attr = dataset[t+1][0]\n",
    "        cur_param = utils.toTensor(dataset[t+1][1])\n",
    "        cur_x = utils.toTensor(dataset[t+1][2])\n",
    "        cur_y = dataset[t+1][3]\n",
    "        print((cur_attr==task_attr_byID[t+1]).all())\n",
    "\n",
    "\n",
    "        reshaped_w = utils.reshape_w(cur_param, shape_record)\n",
    "        pred = model(reshaped_w, cur_x)\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred[pred>=0.5] = torch.ones_like(pred[pred>=0.5])\n",
    "        pred[pred<0.5] = torch.zeros_like(pred[pred<0.5])\n",
    "        print(np.sum(utils.toNumpy(pred)==cur_y)/100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_attributes = '../ZSTL_Data/Animals_with_Attributes2/predicate-matrix-continuous.txt'\n",
    "def gen_attr(path_attributes):\n",
    "    data_attributes = pd.read_csv(path_attributes, sep=\"\\n\", header=None)\n",
    "    print(data_attributes)\n",
    "    lst = []\n",
    "    task_attr_byID = {}\n",
    "    i = 1\n",
    "    for r in data_attributes.iterrows():\n",
    "        # print(len(r), )\n",
    "        s = r[1].to_numpy()\n",
    "        # print(len(s[0].split()), s[0].split())\n",
    "        print(len(s[0].split()))\n",
    "        task_attr_byID[i] = np.array([float(a) for a in s[0].split()])\n",
    "        print(task_attr_byID[i].shape)\n",
    "        i += 1\n",
    "    return task_attr_byID\n",
    "\n",
    "#task_attr_byID = gen_attr(path_attributes)\n",
    "#check_attr_correct(total_len, dataset, task_attr_byID, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10\n140\n50\n"
    }
   ],
   "source": [
    "np.random.seed(666)\n",
    "indx = [ x+1 for x in range(len(dataset))]\n",
    "support_indx = list(np.random.choice(indx, size=kb_size, replace=False))\n",
    "print(len(support_indx))\n",
    "temp = [x for x in indx if x not in support_indx]\n",
    "train_indx = list(np.random.choice(temp, size=train_size, replace=False))\n",
    "temp = [x for x in temp if x not in train_indx]\n",
    "print(len(train_indx))\n",
    "test_indx = temp\n",
    "print(len(test_indx))\n",
    "\n",
    "\n",
    "support_data = utils.Dataset([dataset[d] for d in support_indx])\n",
    "train_data = utils.Dataset([dataset[d] for d in train_indx])\n",
    "test_data = utils.Dataset([dataset[d] for d in test_indx])\n",
    "support_loader = DataLoader(support_data, batch_size=kb_size, shuffle=False)\n",
    "train_loader = DataLoader(train_data, batch_size=train_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "312\n2049\n{'rho': 1e-05, 'mu': 1e-05, 'loss': 'binary class', 'outer lr': 0.001, 'align lr': 0.001, 'dm': 312, 'd': 2049, 'model_shape': {0: [(1, 2049)]}, 'atten_activation': 'Sparsemax'}\ninit mean test metric 0.5932499999999999; align loss 0.15442827343940735\n1/1500 o_loss 0.6687120677437633; m train metric 0.5103571428571431; m test metric 0.5132499999999999; align loss  0.14869605004787445\n100/1500 o_loss 0.6454023142644604; m train metric 0.6550892857142858; m test metric 0.63475; align loss  0.13971823453903198\n200/1500 o_loss 0.6397499790082553; m train metric 0.6656250000000002; m test metric 0.6459999999999999; align loss  0.1282854825258255\n300/1500 o_loss 0.6326063864731363; m train metric 0.6772321428571427; m test metric 0.64575; align loss  0.11754855513572693\n400/1500 o_loss 0.6250829269776919; m train metric 0.6885714285714284; m test metric 0.64475; align loss  0.1027536690235138\n500/1500 o_loss 0.6156067197011518; m train metric 0.7030357142857143; m test metric 0.6465; align loss  0.08923690766096115\n600/1500 o_loss 0.6143226539117417; m train metric 0.7030357142857144; m test metric 0.6497499999999998; align loss  0.07842089235782623\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6d4178f2e7c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mZSTL_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZSTL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mZSTL_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Thesis_code/ZSTL_Master_Thesis/ZSTL_GPU.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, test_loader, max_iter)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mtrain_l_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mo_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "support_a, support_w, support_x, support_y = next(iter(support_loader))\n",
    "support_a, support_w, support_x, support_y = support_a.float(), support_w.float(), support_x.float(), support_y.float()\n",
    "support_a = support_a.squeeze().t()\n",
    "support_w = support_w.squeeze().t()\n",
    "dm = support_a.size()[0]\n",
    "print(dm)\n",
    "d  = support_w.size()[0]\n",
    "print(d)\n",
    "\n",
    "param_dict = {}\n",
    "param_dict['rho'] = 1e-5\n",
    "param_dict['mu'] = 1e-5\n",
    "param_dict['loss'] = 'binary class'\n",
    "param_dict['outer lr'] = 1e-3\n",
    "param_dict['align lr'] = 1e-3\n",
    "param_dict['dm'] = dm\n",
    "param_dict['d'] = d\n",
    "param_dict['model_shape'] = shape_record\n",
    "param_dict['atten_activation'] = 'Sparsemax'\n",
    "print(param_dict)\n",
    "\n",
    "\n",
    "ZSTL_model = ZSTL(support_w, support_a, support_x, net, param_dict, device)\n",
    "ZSTL_model.train(train_loader, test_loader, max_iter=1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "indx = train_indx\n",
    "val_indx = list(np.random.choice(indx, size=20, replace=False))\n",
    "print(len(val_indx))\n",
    "train_indx_splited = [x for x in indx if x not in val_indx]\n",
    "print(len(train_indx_splited))\n",
    "\n",
    "val_data = utils.Dataset([dataset[d] for d in val_indx])\n",
    "train_splited_data = utils.Dataset([dataset[d] for d in train_indx_splited])\n",
    "val_loader = DataLoader(val_data, batch_size=len(val_indx), shuffle=True)\n",
    "train_splited_loader = DataLoader(train_splited_data, batch_size=len(train_indx_splited), shuffle=True)\n",
    "\n",
    "best_hp = utils.hp_select_binClass(train_splited_loader, val_loader, support_loader, d, dm, net, shape_record)\n",
    "print('best_hp ', best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2049 312\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_dict = {}\n",
    "param_dict['rho'] = best_hp['rho']\n",
    "param_dict['mu'] = best_hp['mu']\n",
    "param_dict['loss'] = 'binary class'\n",
    "param_dict['outer lr'] = 1e-3\n",
    "param_dict['align lr'] = 1e-4\n",
    "param_dict['dm'] = dm\n",
    "param_dict['d'] = d\n",
    "param_dict['model_shape'] = shape_record\n",
    "param_dict['atten_activation'] = 'Sparsemax'\n",
    "print(param_dict)\n",
    "\n",
    "\n",
    "ZSTL_model = ZSTL(support_w, support_a, support_x, net, param_dict)\n",
    "ZSTL_model.train(train_loader, test_loader, max_iter=1800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}